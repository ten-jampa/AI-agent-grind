{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fd7c61",
   "metadata": {},
   "source": [
    "# Building a minimal ReAct AI agent\n",
    "\n",
    "The goal is to build a simple LangChain-powered agent that:\n",
    "- Takes a user query\n",
    "- Decides what tool to use (calculator or web search)\n",
    "- Calls the tool\n",
    "- Returns an answer\n",
    "\n",
    "We'll use \n",
    "- Langchain\n",
    "- Gemini (via ```google.generativeai```)\n",
    "- tool (Calculator)\n",
    "- ReAct-style logic (Reason + action + Observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c06441",
   "metadata": {},
   "source": [
    "## End-to-End agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba3432",
   "metadata": {},
   "source": [
    "## Task 1: Imports and instantiate the central model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7312fd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Langchain is a framework designed to simplify the development of applications powered by large language models (LLMs). Think of it as a toolkit that helps you connect LLMs to other data sources and tools, allowing you to build more sophisticated and useful applications.\n",
       "\n",
       "Here's a breakdown of what it is and why it's useful:\n",
       "\n",
       "**Core Concepts:**\n",
       "\n",
       "* **LLMs (Large Language Models):**  These are the powerful AI models like GPT-3, GPT-4, PaLM, Llama 2, etc., that can generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way. Langchain helps you work with these models.\n",
       "\n",
       "* **Components:** Langchain provides modular components that you can assemble to create different types of applications.  These components include:\n",
       "    * **Models:**  Wrappers around different LLMs, making them easy to use within Langchain.\n",
       "    * **Prompts:**  Templates and tools for crafting effective prompts to guide the LLM's behavior.  Prompt engineering is crucial for getting the desired output.\n",
       "    * **Chains:**  Sequences of calls to LLMs or other utilities.  This allows you to create complex workflows, like summarizing a document and then answering questions about it.\n",
       "    * **Indexes:**  Ways to structure documents so that LLMs can easily retrieve relevant information from them.  This is essential for working with large datasets.\n",
       "    * **Memory:**  Allows chains and agents to remember previous interactions, enabling conversational applications.\n",
       "    * **Agents:**  Use an LLM to decide which actions to take, allowing them to interact with the outside world (e.g., using search engines, calculators, or other APIs).\n",
       "    * **Callbacks:**  Hooks that allow you to inspect and modify the execution of chains and agents.  Useful for logging, debugging, and monitoring.\n",
       "\n",
       "**Why is Langchain Useful?**\n",
       "\n",
       "* **Abstraction:**  It abstracts away the complexities of working directly with LLM APIs.  You don't need to worry about the low-level details of authentication, rate limiting, or data formatting.\n",
       "\n",
       "* **Modularity:**  The modular design allows you to easily swap out different components (e.g., different LLMs, different vector databases) without rewriting your entire application.\n",
       "\n",
       "* **Composability:**  You can combine different components to create complex and powerful applications.\n",
       "\n",
       "* **Standardization:**  Langchain provides a standardized way to interact with LLMs, making it easier to build applications that are portable and maintainable.\n",
       "\n",
       "* **Community and Ecosystem:**  Langchain has a large and active community, which means there are plenty of resources, examples, and support available.  It also integrates with a wide range of other tools and services.\n",
       "\n",
       "**What can you build with Langchain?**\n",
       "\n",
       "* **Chatbots:**  Build conversational AI agents that can answer questions, provide support, or even just chat.\n",
       "* **Question Answering Systems:**  Create systems that can answer questions based on a specific set of documents or data.\n",
       "* **Summarization Tools:**  Automatically summarize long documents or articles.\n",
       "* **Code Generation Tools:**  Generate code from natural language descriptions.\n",
       "* **Data Analysis Tools:**  Use LLMs to analyze data and generate insights.\n",
       "* **Agents that can take actions:**  Build agents that can use tools like search engines, calculators, and APIs to accomplish tasks.\n",
       "\n",
       "**In summary, Langchain is a powerful framework that simplifies the process of building applications powered by large language models. It provides a set of tools and abstractions that make it easier to connect LLMs to other data sources and tools, allowing you to create more sophisticated and useful applications.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "from google import genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from load_env import gemini_api_key\n",
    "from langchain_core.messages import HumanMessage\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Create a model instance\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = 'gemini-2.0-flash',\n",
    "    api_key = gemini_api_key,\n",
    "    temperature = 0.3,\n",
    "    max_tokens = 1500,\n",
    "    timeout = None,\n",
    "    max_retries = 2,\n",
    "    # some other parameters\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "response = llm.invoke('Hello! What is Langchain?')\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f451e",
   "metadata": {},
   "source": [
    "## Task 2: Defining tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "709c92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "import math\n",
    "\n",
    "# we want a function that takes a string and returns the resuly\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluates a math expression using Python's math library.\n",
    "    You can use functions like sin, cos, sqrt, log, and constants like pi.\n",
    "    Example: math.sin(30 * pi / 180)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    try:\n",
    "        result = eval(expression, {'__builtin__': {}, 'math': math})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test the tool\n",
    "print(calculate.invoke('2+2'))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43afccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-community) (0.3.68)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.14-cp313-cp313-macosx_10_13_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-community) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-community) (0.4.5)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain-community)\n",
      "  Using cached numpy-2.3.1-cp313-cp313-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.7.0-cp313-cp313-macosx_10_13_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.6.3-cp313-cp313-macosx_10_13_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.2-cp313-cp313-macosx_10_13_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.1-cp313-cp313-macosx_10_13_x86_64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: anyio in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.14-cp313-cp313-macosx_10_13_x86_64.whl (473 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached numpy-2.3.1-cp313-cp313-macosx_14_0_x86_64.whl (6.6 MB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp313-cp313-macosx_10_13_x86_64.whl (47 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.6.3-cp313-cp313-macosx_10_13_x86_64.whl (45 kB)\n",
      "Using cached propcache-0.3.2-cp313-cp313-macosx_10_13_x86_64.whl (42 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp313-cp313-macosx_10_13_x86_64.whl (90 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 numpy-2.3.1 propcache-0.3.2 pydantic-settings-2.10.1 typing-inspect-0.9.0 yarl-1.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bdc2c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U duckduckgo-search --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3d5ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1 day ago · Clubs from across the globe have competed in the FIFA Club World '\n",
      " 'Cup over the last 25 years, with the latest edition featuring giants from '\n",
      " 'all six of world soccer’s governing … 1 day ago · Chelsea beat Paris '\n",
      " 'Saint-Germain 3-0 at the FIFA Club World Cup final in front of U.S. '\n",
      " 'President Donald Trump. See all the goals and highlights. Jun 23, 2025 · A '\n",
      " 'complete record of FIFA Club World Cup winners since 2000, highlighting '\n",
      " 'major format changes and key moments in tournament history. 21 hours ago · '\n",
      " 'The FIFA Club World Cup expanded to a 32-team quadrennial event in 2025. '\n",
      " 'Real Madrid has won the tournament a record five times, claiming victory in '\n",
      " '2014, 2016, 2017, 2018 … 1 day ago · Chelsea have won the FIFA Club World '\n",
      " 'Cup after an impressive 3-0 victory over UEFA Champions League winner Paris '\n",
      " 'Saint-Germain in the final in New Jersey. The Blues were brilliant …')\n"
     ]
    }
   ],
   "source": [
    "# let's set up a web search tool\n",
    "# for a minimal demo, we can use a simple web search\n",
    "# like DuckDuckGo\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# create the search tool\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Test the tool\n",
    "response = search.invoke('Who won the Fifa Club world cup?')\n",
    "from pprint import pprint\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb2d77",
   "metadata": {},
   "source": [
    "## Task 3: Define the Agent's Prompt and Tool list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "083b095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [calculate, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404f4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's how to find the square root of 144:\\n\\n*   **Understanding Square Root:** The square root of a number is a value that, when multiplied by itself, equals the original number.\\n\\n*   **Calculation:** The square root of 144 is 12 because 12 * 12 = 144.\\n\\n**Answer:** The square root of 144 is 12.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--5a54d352-ad74-4a4a-bf30-082b559026e1-0', usage_metadata={'input_tokens': 46, 'output_tokens': 93, 'total_tokens': 139, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        'system', \n",
    "        'You are a helpful AI assistant. You have access to the following tools: calculator, web search. Use them first of all to answer user questions. Think step by step.'\n",
    "    ),\n",
    "    ('user', '{input}')\n",
    "])\n",
    "\n",
    "chain = prompt | llm #do chain prompting\n",
    "\n",
    "response = chain.invoke({'input': 'What is the square root of 144?'})\n",
    "response # this response is not good, it is not using the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66af82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the agent class\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools = tools,\n",
    "    llm = llm,\n",
    "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to calculate the square root of 144. I can use the calculate tool for this.\n",
      "Action: calculate\n",
      "Action Input: sqrt(144)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'sqrt' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI made a mistake by assuming the `calculate` tool knows the `sqrt` function. I should instead use the power operator to calculate the square root.\n",
      "Action: calculate\n",
      "Action Input: 144**0.5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m12.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 12.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the square root of 144? You can use math library for the calculate tool', 'output': '12.0'}\n"
     ]
    }
   ],
   "source": [
    "# invoke the agent\n",
    "response = agent.invoke('What is the square root of 144?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24dda71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI know that the sine of 30 degrees is a common trigonometric value.\n",
      "Action: calculate\n",
      "Action Input: sin(30)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'sin' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to use a calculator that understands trigonometric functions. I'll try expressing 30 degrees in radians and then using the math library.\n",
      "Action: calculate\n",
      "Action Input: sin(30 * pi / 180)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'sin' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to use a calculator that understands trigonometric functions. I will try to use duckduckgo search to find the answer.\n",
      "Action: duckduckgo_search\n",
      "Action Input: sin(30 degrees)\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mNov 22, 2024 · To determine the sine and cosine of 30 degrees, we can use the special values known in trigonometry for this angle. Sine of 30°: The sine function represents the ratio of the … Mar 16, 2025 · Sin (30) = 0.5 All the trig. values are based on a triangle integrated into a circle. Practically, On a piece of graph paper, draw a circle centred on the origin (0,0). Call the radius of … Aug 11, 2024 · What is the value of sin 30 degrees? The value of \\sin 30^\\circ (sine of 30 degrees) is a fundamental trigonometric value that is commonly used in various fields of mathematics and … Oct 22, 2018 · Answer: the derivative of sin 30 degrees will be zero. Step-by-step explanation: First of all, we need to know what is the value of sin 30 degrees. Step 1:- According to the … May 23, 2018 · Find an answer to your question Find the value of sin 30 degree geometrically.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results indicate that sin(30 degrees) = 0.5\n",
      "Final Answer: 0.5\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the sin of 30 degrees?', 'output': '0.5'}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke('What is the sin of 30 degrees?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ab1d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the sine of 3.14 radians. I can use the calculate tool for this.\n",
      "Action: calculate\n",
      "Action Input: sin(3.14)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'sin' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to calculate the sine of 3.14 radians. I need to use the calculate tool, but it seems it doesn't recognize the sin function. I will try using the math.sin function.\n",
      "Action: calculate\n",
      "Action Input: math.sin(3.14)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m0.0015926529164868282\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sine of 3.14 radians.\n",
      "Final Answer: 0.0015926529164868282\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the sin of 3.14 radians??',\n",
       " 'output': '0.0015926529164868282'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.invoke('What is the sin of 3.14 radians??')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9977c",
   "metadata": {},
   "source": [
    "## Task 4: Test and Refine your agent\n",
    "Test your agent with a variety of queries to ensure it uses the right tool and handles edge cases. Refine tool docstrings or logic as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9caaadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to calculate the product of 12 and 15.\n",
      "Action: calculate\n",
      "Action Input: 12 * 15\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m180\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 180\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is 12 multiplied by 15?', 'output': '180'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFirst, I need to calculate the square of 144.\n",
      "Action: calculate\n",
      "Action Input: 144*144\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m20736\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 42\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mNow I need to raise the result (20736) to the power of 1/3, which is the same as taking the cube root.\n",
      "Action: calculate\n",
      "Action Input: 20736**(1/3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m27.47314182127996\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 40\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m queries = [\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mWhat is 12 multiplied by 15?\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mWhat is the square of 144, raised to the power of 1/3?. Break the calculations into steps\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mwhat is tan(sin(75)). Break the calculation to help?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m ]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/chains/base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/chains/base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/agents/agent.py:1620\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1618\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1628\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1629\u001b[39m             next_step_output, intermediate_steps, run_manager=run_manager\n\u001b[32m   1630\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/agents/agent.py:1328\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1319\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1324\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m   1326\u001b[39m         \u001b[43m[\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1336\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/agents/agent.py:1354\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1351\u001b[39m     intermediate_steps = \u001b[38;5;28mself\u001b[39m._prepare_intermediate_steps(intermediate_steps)\n\u001b[32m   1353\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/agents/agent.py:800\u001b[39m, in \u001b[36mAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[32m    789\u001b[39m \n\u001b[32m    790\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    797\u001b[39m \u001b[33;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[32m    798\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    799\u001b[39m full_inputs = \u001b[38;5;28mself\u001b[39m.get_full_inputs(intermediate_steps, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m full_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfull_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_parser.parse(full_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/chains/llm.py:319\u001b[39m, in \u001b[36mLLMChain.predict\u001b[39m\u001b[34m(self, callbacks, **kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    305\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    317\u001b[39m \u001b[33;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m.output_key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:189\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/chains/base.py:386\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m    356\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m config = {\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    382\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    384\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/chains/base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/chains/base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/chains/llm.py:127\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    125\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    126\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain/chains/llm.py:139\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    137\u001b[39m callbacks = run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.llm.bind(stop=stop, **\u001b[38;5;28mself\u001b[39m.llm_kwargs).batch(\n\u001b[32m    147\u001b[39m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks}\n\u001b[32m    148\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1441\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1415\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1416\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1427\u001b[39m     **kwargs: Any,\n\u001b[32m   1428\u001b[39m ) -> ChatResult:\n\u001b[32m   1429\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1430\u001b[39m         messages,\n\u001b[32m   1431\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1439\u001b[39m         **kwargs,\n\u001b[32m   1440\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:231\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    224\u001b[39m params = (\n\u001b[32m    225\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    230\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/tenacity/__init__.py:336\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    334\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    335\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/tenacity/__init__.py:475\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/tenacity/__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    374\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/tenacity/__init__.py:418\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    416\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/tenacity/__init__.py:185\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/tenacity/__init__.py:478\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    480\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:222\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    219\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:206\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 40\n}\n]"
     ]
    }
   ],
   "source": [
    "## math queries\n",
    "queries = [\n",
    "    'What is 12 multiplied by 15?',\n",
    "    'What is the square of 144, raised to the power of 1/3?. Break the calculations into steps',\n",
    "    'what is tan(sin(75)). Break the calculation to help?'\n",
    "]\n",
    "for query in queries:\n",
    "    print(agent.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb40e45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out who the current president of France is. I can use a search engine to find this information.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"president of France\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m1 day ago · Emmanuel Macron is a French banker and politician who was elected president of France in 2017. Macron was the first person in the history of the Fifth Republic to win the … Dec 5, 2024 · Emmanuel Macron vows to stay in office until 2027 and names a new prime minister after a historic no-confidence vote at the National Assembly. He blames his opponents … Dec 5, 2024 · French President Emmanuel Macron faces the challenge to pick a prime minister capable of leading a minority government in a parliament where no party holds a majority. Dec 6, 2024 · French President Emmanuel Macron addresses the nation following the resignation of ousted Prime Minister Michel Barnier, a day after a historic no-confidence vote at the … 6 days ago · Emmanuel Macron is on a three-day state visit to the UK, the first by a French president since 2008. Watch live below as he addresses parliament - after a carriage …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results indicate that Emmanuel Macron is the current president of France.\n",
      "Final Answer: Emmanuel Macron\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Who is the president of France?', 'output': 'Emmanuel Macron'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the capital of Tibet. I will use a search engine to find the answer.\n",
      "Action: duckduckgo_search\n",
      "Action Input: capital of Tibet\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mDec 20, 2022 · Lhasa is the capital city of Tibet before 1959. It was the administrative center of Tibet and Gaden Podrang was the name of the government. After Chinese invasion, Tibetan … No, the capital of Tibet is Lhasa. Nepal is a country not a capital. May 3, 2024 · Canberra is the capital city of Australia. the capital is Berlin. Rome. Rome is the capital of Italy and is nicknamed the Eternal City. It runs through the eastern banks of the river … Oct 6, 2023 · One View:The common people in Tibet eat mutton, beef and meat of yak. Some of the Buddhists prefer vegetarian food.Tibetans have rice, wheat and barley as staple foods, … The capital city of Tibet is Lhasa.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the answer.\n",
      "Final Answer: Lhasa\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the capital of Tibet?', 'output': 'Lhasa'}\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    'Who is the president of France?',\n",
    "    'What is the capital of Tibet?'\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(agent.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95e3a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the population of Germany first, then divide it by 2.\n",
      "Action: duckduckgo_search\n",
      "Action Input: population of Germany\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mFeb 16, 2025 · The estimated population of Germany in 1941 was around 70 million people. Apr 26, 2024 · In the 1930s, the population of Germany was approximately 67 million people. Oct 27, 2022 · In 1939 the population of Germany (including annexed Austria, Memelland, and the Sudetenland) was … Sep 1, 2023 · In 1914 Germany had a population of 67 million. Berlin was the capital and Kaiser Wilhelm II was the … Feb 16, 2025 · The population of Germany in 1941 was approximately 69 million.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the current population of Germany.\n",
      "Action: duckduckgo_search\n",
      "Action Input: current population of Germany\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAug 7, 2018 · You mention over due bills. If your missing credits follow late payments, that’s your answer. Pay EVERY bill on time without fail and the problem may resolve. … Oct 31, 2020 · my current router, 2Wire 3801 HGV-B, it's OLD and I NEED A BETTER REPLACEMENT! HOW CAN I GET A NEW MODEL? has an issue with intermittently … May 22, 2018 · Just move the SIM card from your current phone to the new phone. If the new phone takes a different size, go to an ATT store for a replacement, they will activate it … Aug 13, 2018 · When reviewing usage logs for \"Current Billed Usage (Jun xx, 2018- Jul yy,2018), the itemized text log shows the occurrences correctly with regards to … Sep 18, 2017 · Is there a way an agent or representative can check 10 days of current billing cycle to turn in for business expense …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the current population of Germany.\n",
      "Action: duckduckgo_search\n",
      "Action Input: current population of Germany\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m2 days ago · In Germany, the population is 84,056,081 as of Saturday, July 12, 2025, with a growth rate of -0.79% per year, 1,940 births per day, and 2,854 deaths per day. The population of Germany is equivalent to 1.03% of the world's total's population. 5 days ago · The current population of Germany is 84,060,105 with an annual growth rate of -0.794%. Germany has … 76 rows · Feb 7, 2025 · The current population of Germany is 84,062,235 as of July 09, 2025, based on … Jun 20, 2025 · As of the end of 2024, Germany's population stood at just under 83.6 million, an increase of 121,000 … Jun 28, 2025 · By the end of 2024, Germany’s population reached nearly 83.6 million people, marking the …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe current population of Germany is approximately 84,062,235. Now I need to divide this number by 2.\n",
      "Action: calculate\n",
      "Action Input: 84062235 / 2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m42031117.5\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 42031117.5\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the population of Germany divided by 2? Think in steps', 'output': '42031117.5'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis is a tricky question. I need to find the current temperature in New York, then calculate the cosine of that temperature. The temperature will be in degrees (likely Fahrenheit or Celsius). I'll use DuckDuckGo to find the current temperature in New York. Then I'll use the calculator to find the cosine.\n",
      "\n",
      "Action: duckduckgo_search\n",
      "Action Input: current temperature in New York\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAug 7, 2018 · You mention over due bills. If your missing credits follow late payments, that’s your answer. Pay EVERY bill on time without fail and the problem may resolve. Once suspended, … Oct 31, 2020 · my current router, 2Wire 3801 HGV-B, it's OLD and I NEED A BETTER REPLACEMENT! HOW CAN I GET A NEW MODEL? has an issue with intermittently resetting … May 22, 2018 · Just move the SIM card from your current phone to the new phone. If the new phone takes a different size, go to an ATT store for a replacement, they will activate it with your … Aug 13, 2018 · When reviewing usage logs for \"Current Billed Usage (Jun xx, 2018- Jul yy,2018), the itemized text log shows the occurrences correctly with regards to date/time; contact #; … Sep 18, 2017 · Is there a way an agent or representative can check 10 days of current billing cycle to turn in for business expense report??\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe previous search result was not helpful. I need to refine my search query to get the current temperature.\n",
      "\n",
      "Action: duckduckgo_search\n",
      "Action Input: current temperature in New York City\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mCheck current conditions in New York, NY with radar, hourly, and more. Get New York, NY current weather report with temperature, feels like, wind, humidity, pressure, UV and more from TheWeatherNetwork.com. Today’s and tonight’s Manhattan, NY weather forecast, weather conditions and Doppler radar from The Weather Channel and Weather.com 4 days ago · Currently: 87 °F. Passing clouds. (Weather station: New York City - Central Park, USA). See more current weather 1 day ago · Tomorrow's temperature is forecast to be NEARLY THE SAME as today. New York City Weather Forecasts. Weather Underground provides local & long-range weather forecasts, …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe current temperature in New York City is 87°F. Now I need to calculate the cosine of 87. Since the cosine function typically takes radians as input, I will assume the question is asking for the cosine of 87 radians.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: cos(87)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'cos' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe calculator doesn't recognize 'cos' directly. I need to use the math module.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: import math; math.cos(87)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: invalid syntax (<string>, line 1)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to use the calculator correctly. It seems like I can only input a simple expression. I will need to convert 87 radians to degrees, or find a calculator that can handle radians. I'll assume the temperature is in degrees Fahrenheit and convert it to radians first.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: 87 * pi / 180\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'pi' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to define pi.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: 87 * 3.14159265359 / 180\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1.5184364492351667\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I have the temperature in radians. I can calculate the cosine.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: cos(1.5184364492351667)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'cos' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI still can't use cos directly. I need to find a way to calculate the cosine of the temperature in radians. I will try to search for a cosine calculator online.\n",
      "\n",
      "Action: duckduckgo_search\n",
      "Action Input: cosine calculator\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mInverse cosine calculator -1 = Calculate Reset Degrees First result Second result Use this cos calculator to easily calculate the cosine of an angle given in degrees or radians. The cosine is encountered in … Effortlessly find trigonometric function values (sin, cos, tan, cot) or solve for missing sides or angles in a right … The online free cosine calculator helps in calculating the cosine value of the given angle in degrees, radians, mili-radians, … Use the cos calculator to find the cosine of an angle in radians or degrees, plus learn the trigonometric formulas and …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will use the value I calculated earlier (1.5184364492351667 radians) and input it into the cosine calculator I found online. Since I can't directly interact with the online calculator, I will use the calculate tool with the assumption that it can handle the cosine function if I input the radian value directly.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: cos(1.5184364492351667)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'cos' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI am still unable to calculate the cosine directly. I will try using Python's math module within the calculate tool.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: import math; print(math.cos(1.5184364492351667))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: invalid syntax (<string>, line 1)\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI am still unable to calculate the cosine. It seems the calculate tool is very limited. I will try to approximate the cosine using a Taylor series expansion. The cosine of x is approximately 1 - x^2/2 + x^4/24.\n",
      "\n",
      "Action: calculate\n",
      "Action Input: 1 - (1.5184364492351667)**2 / 2 + (1.5184364492351667)**4 / 24\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m0.06867614422175114\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have approximated the cosine of the temperature in radians.\n",
      "\n",
      "Final Answer: 0.06867614422175114\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the cosine of the current temperature in New york?', 'output': '0.06867614422175114'}\n"
     ]
    }
   ],
   "source": [
    "# Mixed\n",
    "queries = [\n",
    "    'What is the population of Germany divided by 2? Think in steps',\n",
    "    'What is the cosine of the current temperature in New york?'\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(agent.invoke(query))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1251f282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to convert centimeters to yards. I can use the search tool to find the conversion factor.\n",
      "Action: duckduckgo_search\n",
      "Action Input: convert cm to yards\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mNo good DuckDuckGo Search Result was found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to convert centimeters to yards. I can use the search tool to find the conversion factor.\n",
      "Action: duckduckgo_search\n",
      "Action Input: cm to yards conversion factor\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mInstant free online tool for centimeter to inch conversion or vice versa. The centimeter [cm] to inch [in] conversion table and conversion steps are also listed. Also, explore tools to convert centimeter or inch to other length … Jan 27, 2023 · Convert quickly and easily between centimeters (cm) and inches (in) using our conversion tool. Our converter … Do a quick conversion: 1 centimetres = 0.39370078740157 inches using the online calculator for metric conversions. Check the chart for more details. To convert a measurement in centimeters to inches, simply divide the number of centimeters by 2.54. For example, if you have a measurement of 50 centimeters, you would divide 50 by 2.54 to get the equivalent … A centimetre (International spelling) or centimeter (American English), with SI symbol cm, is a unit of length in the International System of Units (SI) equal to one hundredth of a metre, centi- being the SI prefix for a …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to convert cm to yards. The search results indicate that 1 cm is approximately 0.3937 inches. I also know that 1 yard is 36 inches. Therefore, I can convert cm to inches and then inches to yards.\n",
      "\n",
      "First, convert 165 cm to inches: 165 cm * 0.3937 inches/cm = 64.9605 inches.\n",
      "Then, convert 64.9605 inches to yards: 64.9605 inches / 36 inches/yard = 1.80445833333 yards.\n",
      "I can use the calculate tool to perform these calculations.\n",
      "Action: calculate\n",
      "Action Input: 165 * 0.3937 / 36\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1.8044583333333333\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 1.8044583333333333\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My height in cm is 165cm. what is my height in yards?',\n",
       " 'output': '1.8044583333333333'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke('My height in cm is 165cm. what is my height in yards?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5505c7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the population of Germany first, then divide it by 2.\n",
      "Action: duckduckgo_search\n",
      "Action Input: population of Germany\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAs of 2025, the population of Germany is projected at 84.08 million, compared to 84.55 million in 2024. It is the second-most populous country in Europe and ranks 19th in the world. 5 days ago · The current population of Germany is 84,060,105 with an annual growth rate of -0.794%. Germany has a population of 1.03% of the world's population. The net migration rate of … Jun 20, 2025 · As of the end of 2024, Germany's population stood at just under 83.6 million, an increase of 121,000 compared to the previous year. This marks a slowdown from 2023, when the … Jan 10, 2025 · Table with data on: Population by nationality and sex 1970 to 2023 in Germany. Apr 19, 2025 · On 01 Jul 2025 Germany population will be 80682351 people. It’s -0.01% (6194 people) compared with the population of Germany on 01 Jul 2024. These data (statistics and …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have several estimates for the population of Germany. I will use the most recent estimate, which is 84,060,105. Now I need to divide this number by 2.\n",
      "Action: calculate\n",
      "Action Input: 84060105 / 2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m42030052.5\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 42030052.5\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the population of Germany divided by 2? Think in steps', 'output': '42030052.5'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the current temperature in New York and then calculate the cosine of that temperature. Since I need to find the current temperature, I should use a search engine. After I have the temperature, I can use the calculator to find the cosine.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"current temperature in New York\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m3 days ago · Current conditions at New York City, Central Park (KNYC) Lat: 40.78°N Lon: 73.97°W Elev: 154ft. 2 days ago · New York, New York - Current temperature and weather conditions. Detailed hourly weather forecast for today - including weather conditions, temperature, pressure, humidity, … 1 day ago · Live New York City, NY weather with granular precipitation, radar, barometric pressure, temperatures and wind speeds for today thru Thursday, as you toggle through each … 3 days ago · The weather today in New York City will be hot with temperatures reaching 86°F. During the evening and night time the temperatures will drop to 71 ° F. For deep dive … Jul 4, 2025 · Get New York, NY weather with accurate real-time conditions, 7-day outlooks, and hourly updates. Plan outdoor activities with temperature, precipitation, wind, and severe …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe current temperature in New York City is approximately 86°F. Now I need to calculate the cosine of 86.\n",
      "Action: calculate\n",
      "Action Input: cos(86)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'cos' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the current temperature in New York and then calculate the cosine of that temperature. Since I need to find the current temperature, I should use a search engine. After I have the temperature, I can use the calculator to find the cosine. The current temperature in New York City is approximately 86°F. Now I need to calculate the cosine of 86. The calculator tool does not seem to recognize the cosine function directly. I need to convert the temperature to radians first. 86 degrees is equal to 86 * pi / 180 radians. Then I can calculate the cosine.\n",
      "Action: calculate\n",
      "Action Input: 86 * pi / 180\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: name 'pi' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the current temperature in New York and then calculate the cosine of that temperature. Since I need to find the current temperature, I should use a search engine. After I have the temperature, I can use the calculator to find the cosine. The current temperature in New York City is approximately 86°F. Now I need to calculate the cosine of 86. The calculator tool does not seem to recognize the cosine function directly. I need to convert the temperature to radians first. 86 degrees is equal to 86 * pi / 180 radians. Then I can calculate the cosine. The calculator does not recognize pi. I need to approximate pi.\n",
      "Action: calculate\n",
      "Action Input: 86 * 3.14159265359 / 180\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1.500983156715222\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe current temperature in New York City is approximately 86°F. I need to calculate the cosine of 86 degrees. I have converted 86 degrees to radians, which is approximately 1.500983156715222 radians. Now I need to calculate the cosine of this value. I will search for a calculator that can calculate the cosine of a number in radians.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"cosine of 1.500983156715222 radians\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mJun 24, 2025 · Here are some tips to help you get the right answer using the Cosine Calculator. Understand the Function: The cosine of an angle is defined as the ratio of the adjacent side to … Jun 10, 2025 · Calculate inverse cosine (arccos) values instantly. Enter any value between -1 and 1 to get results in degrees or radians with detailed explanations. Sep 18, 2024 · Converting degrees to radians is a fundamental skill in mathematics, particularly in trigonometry, calculus, and various fields like physics and engineering. This Degrees to Radian … Mar 30, 2025 · The cosine of pi (π) is -1. Here's how you can find that value: Using the Unit Circle The unit circle is a circle with a radius of 1 centered at the origin of a coordinate plane. Angles … 6 days ago · Explain why cos θ ≤ 1 cos ⁡ θ ≤ 1 for any angle θ θ. How many solutions are there to the equation cos(θ) = 0.4 cos ⁡ (θ) = 0.4 between 0∘ 0 ∘ and 360∘ 360 ∘? On a unit circle, the ___ …\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI cannot directly calculate the cosine of a value using the available tools. I can use the search engine to find the answer.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"cosine of 1.500983156715222 radians\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tenzinjampa/Downloads/personal_projects/AI-agent-grind/venv/lib/python3.13/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mNo good DuckDuckGo Search Result was found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI cannot directly calculate the cosine of a value using the available tools. I can use the search engine to find the answer. Since the search engine did not return a direct answer, I will try to calculate the cosine using an online calculator and then provide the answer.\n",
      "\n",
      "Since I cannot perform the calculation with the available tools, I will have to provide an estimated answer. The current temperature in New York is approximately 86 degrees Fahrenheit. Converting this to radians gives approximately 1.5 radians. The cosine of 1.5 radians is approximately 0.07.\n",
      "\n",
      "Final Answer: Approximately 0.07\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the cosine of the current temperature in New york?', 'output': 'Approximately 0.07'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def safe_agent_invoke(agent, query, tries = 0):\n",
    "    if tries > 3:\n",
    "        print(f\"Failed to invoke agent after {tries} attempts\")\n",
    "        return None\n",
    "    try:\n",
    "        return agent.invoke(query)\n",
    "    except Exception as e:\n",
    "        time.sleep(3)\n",
    "        return safe_agent_invoke(agent, query, tries + 1)\n",
    "\n",
    "queries = [\n",
    "    'What is the population of Germany divided by 2? Think in steps',\n",
    "    'What is the cosine of the current temperature in New york?'\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    response = safe_agent_invoke(agent, query)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adc0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
